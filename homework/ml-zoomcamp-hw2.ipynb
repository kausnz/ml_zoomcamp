{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#os.remove('/kaggle/working/housing.csv.2')\n",
    "data='https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv'\n",
    "!wget $data\n",
    "\n",
    "df_org = pd.read_csv('housing.csv')"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:52.988441Z",
     "iopub.execute_input": "2022-09-19T12:44:52.988883Z",
     "iopub.status.idle": "2022-09-19T12:44:53.029859Z",
     "shell.execute_reply.started": "2022-09-19T12:44:52.988848Z",
     "shell.execute_reply": "2022-09-19T12:44:53.028380Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "(df_org.median_house_value.min(), df_org.median_house_value.max())\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.histplot(df_org.median_house_value, bins=50)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:53.032747Z",
     "iopub.execute_input": "2022-09-19T12:44:53.033402Z",
     "iopub.status.idle": "2022-09-19T12:44:53.407906Z",
     "shell.execute_reply.started": "2022-09-19T12:44:53.033362Z",
     "shell.execute_reply": "2022-09-19T12:44:53.406537Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "median_house_value_logs = np.log1p(df_org.median_house_value)\n",
    "sns.histplot(median_house_value_logs, bins=30)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:53.409708Z",
     "iopub.execute_input": "2022-09-19T12:44:53.410268Z",
     "iopub.status.idle": "2022-09-19T12:44:53.728239Z",
     "shell.execute_reply.started": "2022-09-19T12:44:53.410229Z",
     "shell.execute_reply": "2022-09-19T12:44:53.727251Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features\n",
    "For the rest of the homework, you'll need to use only these columns:\n",
    "\n",
    "* 'latitude',\n",
    "* 'longitude',\n",
    "* 'housing_median_age',\n",
    "* 'total_rooms',\n",
    "* 'total_bedrooms',\n",
    "* 'population',\n",
    "* 'households',\n",
    "* 'median_income',\n",
    "* 'median_house_value'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "columns = ['latitude','longitude','housing_median_age','total_rooms','total_bedrooms','population','households','median_income','median_house_value']\n",
    "columns\n",
    "df = df_org[columns].copy()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:53.729376Z",
     "iopub.execute_input": "2022-09-19T12:44:53.730363Z",
     "iopub.status.idle": "2022-09-19T12:44:53.737308Z",
     "shell.execute_reply.started": "2022-09-19T12:44:53.730316Z",
     "shell.execute_reply": "2022-09-19T12:44:53.736101Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 1\n",
    "Find a feature with missing values. How many missing values does it have?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:53.740309Z",
     "iopub.execute_input": "2022-09-19T12:44:53.741112Z",
     "iopub.status.idle": "2022-09-19T12:44:53.756152Z",
     "shell.execute_reply.started": "2022-09-19T12:44:53.741073Z",
     "shell.execute_reply": "2022-09-19T12:44:53.755103Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 2\n",
    "What's the median (50% percentile) for variable 'population'?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df.population.median()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:53.757755Z",
     "iopub.execute_input": "2022-09-19T12:44:53.758381Z",
     "iopub.status.idle": "2022-09-19T12:44:53.769206Z",
     "shell.execute_reply.started": "2022-09-19T12:44:53.758342Z",
     "shell.execute_reply": "2022-09-19T12:44:53.767968Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split the data\n",
    "* Shuffle the initial dataset, use seed 42.\n",
    "* Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
    "* Make sure that the target value ('median_house_value') is not in your dataframe.\n",
    "* Apply the log transformation to the median_house_value variable using the np.log1p() function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "n = len(df)\n",
    "n_test = int(n * 0.2) # no. of elements for testing\n",
    "n_valid = int(n * 0.2) # no. of elements for validation\n",
    "n_train = n - n_valid - n_test # the rest if for training\n",
    "(n, (n_train, n_valid, n_test), n_train + n_valid + n_test)\n",
    "\n",
    "idx = np.arange(n)\n",
    "idx\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(idx)\n",
    "idx\n",
    "\n",
    "df_train = df.iloc[idx[:n_train]]\n",
    "df_valid = df.iloc[idx[n_train: n_train + n_valid]]\n",
    "df_test = df.iloc[idx[n_train + n_valid: ]]\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_valid = df_valid.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "(len(df_train), len(df_valid), len(df_test))\n",
    "\n",
    "# taregt vars in log1p form\n",
    "y_train = np.log1p(df_train.median_house_value.values)\n",
    "y_valid = np.log1p(df_valid.median_house_value.values)\n",
    "y_test = np.log1p(df_test.median_house_value.values)\n",
    "\n",
    "# remove target variable from the datasets\n",
    "del df_train['median_house_value']\n",
    "del df_valid['median_house_value']\n",
    "del df_test['median_house_value']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:53.770988Z",
     "iopub.execute_input": "2022-09-19T12:44:53.771365Z",
     "iopub.status.idle": "2022-09-19T12:44:53.789908Z",
     "shell.execute_reply.started": "2022-09-19T12:44:53.771330Z",
     "shell.execute_reply": "2022-09-19T12:44:53.788535Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 3\n",
    "* We need to deal with missing values for the column from Q1.\n",
    "* We have two options: fill it with 0 or with the mean of this variable.\n",
    "* Try both options. For each, train a linear regression model without regularization using the code from the lessons.\n",
    "* For computing the mean, use the training only!\n",
    "* Use the validation dataset to evaluate the models and compare the RMSE of each option.\n",
    "* Round the RMSE scores to 2 decimal digits using round(score, 2)\n",
    "* Which option gives better RMSE?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def train_linear_regression(X, y):\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    # Create Gram matrix\n",
    "    XTX = X.T.dot(X)\n",
    "    \n",
    "    # Inverse the Gram matrix\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    \n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "    return w_full[0], w_full[1:]\n",
    "\n",
    "def get_rmse(y_pred, y):\n",
    "    se = np.square( y_pred - y)\n",
    "    mse = se.mean()\n",
    "    return np.sqrt(mse)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:53.792172Z",
     "iopub.execute_input": "2022-09-19T12:44:53.792712Z",
     "iopub.status.idle": "2022-09-19T12:44:53.801677Z",
     "shell.execute_reply.started": "2022-09-19T12:44:53.792652Z",
     "shell.execute_reply": "2022-09-19T12:44:53.800386Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Q3.1 Solution with 0 fill"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df_train.isna().sum()\n",
    "\n",
    "# a df_train copy with na's filled with 0\n",
    "df_train_zf = df_train.copy()\n",
    "df_train_zf.total_bedrooms.fillna(0, inplace=True)\n",
    "\n",
    "df_train.isna().sum()\n",
    "df_train_zf.isna().sum()\n",
    "\n",
    "# weights based on 0 filled training data\n",
    "w0_zf, w_zf = train_linear_regression(df_train_zf, y_train)\n",
    "(w0_zf, w_zf)\n",
    "\n",
    "y_pred_zf = w0_zf + df_valid.dot(w_zf)\n",
    "\n",
    "# RMSE for 0 filled based prediction \n",
    "round(get_rmse(y_pred_zf, y_valid), 2) # is 0.3295330365227974"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:53.803133Z",
     "iopub.execute_input": "2022-09-19T12:44:53.803616Z",
     "iopub.status.idle": "2022-09-19T12:44:53.842620Z",
     "shell.execute_reply.started": "2022-09-19T12:44:53.803580Z",
     "shell.execute_reply": "2022-09-19T12:44:53.840921Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Q3.2 Solution with mean fill"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df_train.isna().sum()\n",
    "\n",
    "# a df_train copy with na's filled with mean of df_train.total_bedrooms\n",
    "bdr_mean = df_train.total_bedrooms.mean()\n",
    "df_train_mf = df_train.copy()\n",
    "df_train_mf.total_bedrooms.fillna(bdr_mean, inplace=True)\n",
    "\n",
    "df_train.isna().sum()\n",
    "df_train_mf.isna().sum()\n",
    "\n",
    "# weights based on 'mean' filled training data\n",
    "w0_mf, w_mf = train_linear_regression(df_train_mf, y_train)\n",
    "(w0_mf, w_mf)\n",
    "\n",
    "y_pred_mf = w0_mf + df_valid.dot(w_mf)\n",
    "\n",
    "# RMSE for 0 filled based prediction \n",
    "round(get_rmse(y_pred_mf, y_valid), 2) # is 0.3290195439006032"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:53.845443Z",
     "iopub.execute_input": "2022-09-19T12:44:53.846584Z",
     "iopub.status.idle": "2022-09-19T12:44:53.893704Z",
     "shell.execute_reply.started": "2022-09-19T12:44:53.846511Z",
     "shell.execute_reply": "2022-09-19T12:44:53.892070Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 4\n",
    "* Now let's train a regularized linear regression.\n",
    "* For this question, fill the NAs with 0.\n",
    "* Try different values of `r` from this list: `[0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]`.\n",
    "* Use RMSE to evaluate the model on the validation dataset.\n",
    "* Round the RMSE scores to 2 decimal digits.\n",
    "* Which `r` gives the best RMSE?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def train_linear_regression_reg(X, y, r=0.001):\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    # Create Gram matrix\n",
    "    XTX = X.T.dot(X)\n",
    "    XTX = XTX + r * np.eye(XTX.shape[0])\n",
    "    \n",
    "    # Inverse the Gram matrix\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    \n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "    return w_full[0], w_full[1:]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:53.896216Z",
     "iopub.execute_input": "2022-09-19T12:44:53.897222Z",
     "iopub.status.idle": "2022-09-19T12:44:53.918783Z",
     "shell.execute_reply.started": "2022-09-19T12:44:53.897143Z",
     "shell.execute_reply": "2022-09-19T12:44:53.916721Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train_zf = df_train.copy()\n",
    "df_train_zf.total_bedrooms.fillna(0, inplace=True)\n",
    "\n",
    "r_candidates = [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]\n",
    "\n",
    "for r in r_candidates:\n",
    "    w0, w = train_linear_regression_reg(df_train_zf, y_train, r) #<---- this is training\n",
    "    y_pred = w0 + df_valid.dot(w)\n",
    "    print(('{:f}'.format(r), round(get_rmse(y_pred, y_valid),2)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T12:44:53.921349Z",
     "iopub.execute_input": "2022-09-19T12:44:53.922458Z",
     "iopub.status.idle": "2022-09-19T12:44:53.976004Z",
     "shell.execute_reply.started": "2022-09-19T12:44:53.922388Z",
     "shell.execute_reply": "2022-09-19T12:44:53.974305Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 5\n",
    "* We used seed 42 for splitting the data. Let's find out how selecting the seed influences our score.\n",
    "* Try different seed values: `[0, 1, 2, 3, 4, 5, 6, 7, 8, 9].`\n",
    "* For each seed, do the train/validation/test split with 60%/20%/20% distribution.\n",
    "* Fill the missing values with 0 and train a model without regularization.\n",
    "* For each seed, evaluate the model on the validation dataset and collect the RMSE scores.\n",
    "* What's the standard deviation of all the scores? To compute the standard deviation, use `np.std`.\n",
    "* Round the result to 3 decimal digits (`round(std, 3)`)\n",
    "\n",
    "*Note: Standard deviation shows how different the values are. If it's low, then all values are approximately the same. If it's high, the values are different. If standard deviation of scores is low, then our model is stable.*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "n = len(df)\n",
    "n_test = int(n * 0.2) # no. of elements for testing\n",
    "n_valid = int(n * 0.2) # no. of elements for validation\n",
    "n_train = n - n_valid - n_test # the rest if for training\n",
    "\n",
    "rmse_results = []\n",
    "\n",
    "for s in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:\n",
    "\n",
    "    idx = np.arange(n)\n",
    "    np.random.seed(s)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    df_train = df.iloc[idx[:n_train]]\n",
    "    df_valid = df.iloc[idx[n_train: n_train + n_valid]]\n",
    "    df_test = df.iloc[idx[n_train + n_valid: ]]\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_valid = df_valid.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    y_train = np.log1p(df_train.median_house_value.values)\n",
    "    y_valid = np.log1p(df_valid.median_house_value.values)\n",
    "    y_test = np.log1p(df_test.median_house_value.values)\n",
    "\n",
    "    # remove target variable from the datasets\n",
    "    del df_train['median_house_value']\n",
    "    del df_valid['median_house_value']\n",
    "    del df_test['median_house_value']\n",
    "\n",
    "    #---- \n",
    "\n",
    "    # a df_train copy with na's filled with 0\n",
    "    df_train_zf = df_train.copy()\n",
    "    df_train_zf.total_bedrooms.fillna(0, inplace=True)\n",
    "    df_valid_zf = df_valid.copy()\n",
    "    df_valid_zf.total_bedrooms.fillna(0, inplace=True)\n",
    "\n",
    "    # weights based on 0 filled training data\n",
    "    w0_zf, w_zf = train_linear_regression(df_train_zf, y_train)\n",
    "    (w0_zf, w_zf)\n",
    "\n",
    "    y_pred_zf = w0_zf + df_valid_zf.dot(w_zf)\n",
    "\n",
    "    rmse_results.append(get_rmse(y_pred_zf, y_valid))\n",
    "\n",
    "round(np.std(rmse_results), 3)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T13:07:59.859241Z",
     "iopub.execute_input": "2022-09-19T13:07:59.859692Z",
     "iopub.status.idle": "2022-09-19T13:08:00.054501Z",
     "shell.execute_reply.started": "2022-09-19T13:07:59.859651Z",
     "shell.execute_reply": "2022-09-19T13:08:00.052834Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 6\n",
    "* Split the dataset like previously, use seed 9.\n",
    "* Combine train and validation datasets.\n",
    "* Fill the missing values with 0 and train a model with r=0.001.\n",
    "What's the RMSE on the test dataset?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "n = len(df)\n",
    "n_test = int(n * 0.2) # no. of elements for testing\n",
    "n_valid = int(n * 0.2) # no. of elements for validation\n",
    "n_train = n - n_valid - n_test # the rest if for training\n",
    "\n",
    "idx = np.arange(n)\n",
    "np.random.seed(9)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "df_train = df.iloc[idx[:n_train]]\n",
    "df_valid = df.iloc[idx[n_train: n_train + n_valid]]\n",
    "df_test = df.iloc[idx[n_train + n_valid: ]]\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_valid = df_valid.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = np.log1p(df_train.median_house_value.values)\n",
    "y_valid = np.log1p(df_valid.median_house_value.values)\n",
    "y_test = np.log1p(df_test.median_house_value.values)\n",
    "\n",
    "# remove target variable from the datasets\n",
    "del df_train['median_house_value']\n",
    "del df_valid['median_house_value']\n",
    "del df_test['median_house_value']\n",
    "\n",
    "#---- \n",
    "\n",
    "# a df_train copy with na's filled with 0\n",
    "# df_train_zf = df_train.copy()\n",
    "# df_valid_zf = df_valid.copy()\n",
    "# df_train_zf.total_bedrooms.fillna(0, inplace=True)\n",
    "# df_valid_zf.total_bedrooms.fillna(0, inplace=True)\n",
    "\n",
    "df_test_zf = df_test.copy()\n",
    "df_test_zf.total_bedrooms.fillna(0, inplace=True)\n",
    "df_test_zf\n",
    "\n",
    "\n",
    "df_train_full = pd.concat([df_train, df_valid])\n",
    "df_train_full = df_train_full.reset_index(drop=True)\n",
    "df_train_full.total_bedrooms.fillna(0, inplace=True)\n",
    "\n",
    "y_train_full = np.concatenate([y_train, y_valid])\n",
    "\n",
    "# # weights based on 0 filled training data\n",
    "w0_zf, w_zf = train_linear_regression_reg(df_train_full, y_train_full, r=0.001)\n",
    "\n",
    "y_pred_zf = w0_zf + df_test_zf.dot(w_zf)\n",
    "\n",
    "round(get_rmse(y_pred_zf, y_test), 2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-19T13:30:26.519880Z",
     "iopub.execute_input": "2022-09-19T13:30:26.520341Z",
     "iopub.status.idle": "2022-09-19T13:30:26.568281Z",
     "shell.execute_reply.started": "2022-09-19T13:30:26.520302Z",
     "shell.execute_reply": "2022-09-19T13:30:26.566589Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
