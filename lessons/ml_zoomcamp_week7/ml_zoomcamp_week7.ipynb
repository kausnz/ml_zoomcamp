{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘../data/CreditScoring.csv’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -P \"../data\" -nc 'https://raw.githubusercontent.com/gastonstat/CreditScoring/master/CreditScoring.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/CreditScoring.csv')\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map numerical codes to their real values. The real values were from the R code found under the same repo where the csv was download.\n",
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    0: 'unk'\n",
    "}\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'part-time',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "df.home = df.home.map(home_values)\n",
    "df.marital = df.marital.map(marital_values)\n",
    "df.records = df.records.map(records_values)\n",
    "df.job = df.job.map(job_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like we have some unusual max numbers. We need them to 'na' as they are really missing values.\n",
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=np.nan)\n",
    "\n",
    "# We have only one record where status is 'unk'. This is not useful for us. So delete the record.\n",
    "df = df[df.status != 'unk'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# data is now clean. Now do the train, val, test split.\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=11)\n",
    "print(type(df_train))\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "len(df_train), len(df_val), len(df_test)\n",
    "\n",
    "y_train = (df_train.status == 'default').astype('int')\n",
    "y_val = (df_val.status == 'default').astype('int')\n",
    "y_test = (df_test.status == 'default').astype('int')\n",
    "\n",
    "del df_train['status']\n",
    "del df_val['status']\n",
    "del df_test['status']\n",
    "del df_train['index']\n",
    "del df_val['index']\n",
    "del df_test['index']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model\n",
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#\n",
    "# train the model\n",
    "#\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "y_full_train = (df_full_train.status == 'default').astype(int).values\n",
    "del df_full_train['status']\n",
    "dicts_full_train = df_full_train.to_dict(orient='records')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "X_full_train = dv.fit_transform(dicts_full_train)\n",
    "# dm_full_train = xgb.DMatrix(X_full_train,\n",
    "#                             label=y_full_train,\n",
    "#                             feature_names=dv.get_feature_names_out())\n",
    "dm_full_train = xgb.DMatrix(X_full_train,\n",
    "                            label=y_full_train)  # removed the feature names because otherwise we must pass the feature names when predicting (in the bentoml service. If not the predict.run() fails with an error.)\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'eval_metric': 'auc',\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "\n",
    "    'seed': 1,\n",
    "    'verbosity': 1\n",
    "}\n",
    "\n",
    "evals_result = {}\n",
    "auc_summary = []\n",
    "\n",
    "model = xgb.train(params=xgb_params,\n",
    "                  dtrain=dm_full_train,\n",
    "                  num_boost_round=175,\n",
    "                  evals_result=evals_result)\n",
    "\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BentoML\n",
    "\n",
    "Problem with Pickle is we might not capture what's required by different ML frameworks (e.g. xgboost). BentoML has framework specific methods we can call to perform when serialising the model, so it knows what to capture with the model file.  So it has everything it needs when we deserialize it to perform prediction.\n",
    "\n",
    "* You can start bentoml service manually or have a bentomlfile.yaml in the directory (similar to Dokerfile.yaml)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Model(tag=\"credit_risk_model:5eueuasrlsjce6cp\", path=\"/Users/kaushalya/bentoml/models/credit_risk_model/5eueuasrlsjce6cp/\")"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "bentoml.xgboost.save_model(\"credit_risk_model\", model,\n",
    "                           custom_objects={\n",
    "                               \"dictVectorizer\": dv\n",
    "                           },\n",
    "                           signatures={\n",
    "                               \"predict\": {\n",
    "                                   \"batchable\": True,\n",
    "                                   \"batch_dim\": 0\n",
    "                               }\n",
    "                           })"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# test the model\n",
    "#\n",
    "dicts_test = df_test.to_dict(orient='records')\n",
    "X_test = dv.transform(dicts_test)\n",
    "dm_test = xgb.DMatrix(X_test,\n",
    "                      feature_names=dv.get_feature_names_out())  # make sure you do not do this before saving the model. Otherwise, this go insert the feature_names in the model. We do not want to include the feature names in the model. See my other comment in the block where we train the model.\n",
    "\n",
    "y_pred = model.predict(dm_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Measure performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8216607203948976"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# measure performance\n",
    "#\n",
    "roc_auc_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "['age',\n 'amount',\n 'assets',\n 'debt',\n 'expenses',\n 'home=ignore',\n 'home=other',\n 'home=owner',\n 'home=parents',\n 'home=private',\n 'home=rent',\n 'home=unk',\n 'income',\n 'index',\n 'job=fixed',\n 'job=freelance',\n 'job=others',\n 'job=part-time',\n 'job=unk',\n 'marital=divorced',\n 'marital=married',\n 'marital=separated',\n 'marital=single',\n 'marital=unk',\n 'marital=widow',\n 'price',\n 'records=no',\n 'records=yes',\n 'seniority',\n 'time']"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv.feature_names_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sample record for testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "{'seniority': 10,\n 'home': 'owner',\n 'time': 36,\n 'age': 36,\n 'marital': 'married',\n 'records': 'no',\n 'job': 'freelance',\n 'expenses': 75,\n 'income': 0.0,\n 'assets': 10000.0,\n 'debt': 0.0,\n 'amount': 1000,\n 'price': 1400}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[0].to_dict()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
